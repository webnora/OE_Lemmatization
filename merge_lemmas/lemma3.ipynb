{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import itertools\n",
    "from bs4 import BeautifulSoup\n",
    "path_data = '../../OE_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(s):\n",
    "    for v in [('ġ', 'g'), ('ƿ', 'w'), ('ċ', 'с')]:\n",
    "        s = s.replace(v[0], v[1]) \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nesan\t''unattested''\n",
    "def filter_forms(arr):\n",
    "    return sorted(set(v for v in arr if v not in ['tō', \"''unattested''\", '']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': 'oe.lemmas',\n",
       " 'lemma': 'macian',\n",
       " 'forms': ['gemacod,macod',\n",
       "  'maca',\n",
       "  'macast',\n",
       "  'macaþ',\n",
       "  'macian',\n",
       "  'maciaþ,macigaþ',\n",
       "  'macie,macige',\n",
       "  'macien,macigen',\n",
       "  'maciende,macigende',\n",
       "  'macienne',\n",
       "  'macode',\n",
       "  'macoden',\n",
       "  'macodest',\n",
       "  'macodon']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_oe(file = 'oe.lemmas'):\n",
    "    def make(s):\n",
    "        a = s.split()\n",
    "        return {\n",
    "            \"file\": file,\n",
    "            \"lemma\": a[0],\n",
    "            \"forms\": filter_forms(a[1:])\n",
    "        }\n",
    "    with open(path_data + file, 'r') as f:\n",
    "        arr = normalize(f.read()).split('\\n')\n",
    "        return [make(s) for s in arr if s not in ['', '&\\t&']]\n",
    "load_oe()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_oe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e701fe93e379>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'&\\t&'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mload_oe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'load_oe' is not defined"
     ]
    }
   ],
   "source": [
    "def load_node(file = 'in'):\n",
    "    def make(s):\n",
    "        a = s.split()\n",
    "        return {\n",
    "            \"file\": file,\n",
    "            \"lemma\": a[0],\n",
    "            \"forms\": filter_forms(a[1:])\n",
    "        }\n",
    "    with open(file, 'r') as f:\n",
    "        arr = normalize(f.read()).split('\\n')\n",
    "        return [make(s) for s in arr if s not in ['', '&\\t&']]\n",
    "load_oe()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': 'ang.txt',\n",
       " 'lemma': 'feohtan',\n",
       " 'forms': ['feaht',\n",
       "  'feoht',\n",
       "  'feohtan',\n",
       "  'feohtaþ',\n",
       "  'feohte',\n",
       "  'feohten',\n",
       "  'feohtende',\n",
       "  'fieht',\n",
       "  'fiehtst',\n",
       "  'fohten',\n",
       "  'fuhte',\n",
       "  'fuhten',\n",
       "  'fuhton']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_dict(file = 'ang.txt'):\n",
    "    def make(w):\n",
    "        return {\n",
    "            \"file\": file,\n",
    "            \"lemma\": w.split()[0],\n",
    "            \"forms\": filter_forms([l.split()[1] for l in w.split('\\n')])\n",
    "        }\n",
    "    with open(path_data + file, 'r') as f:\n",
    "        arr = normalize(f.read()).split('\\n\\n')\n",
    "        return [make(w) for w in arr if len(w) != 0]\n",
    "load_dict()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_node(limit = 100000000, file = 'texts/BT/node.csv'):\n",
    "    def pars_grammar(s):\n",
    "        gr = BeautifulSoup(s).find('grammar')\n",
    "        if not gr: return []\n",
    "        group = ''.join(gr.findAll(text=True, recursive=False)).split(';')\n",
    "        res = [item.strip() for sublist in (g.split(',') for g in group) for item in sublist]\n",
    "#         print(gr.prettify())\n",
    "#         print('====>', res)\n",
    "        return res\n",
    "    def _filter(w):\n",
    "#         return True\n",
    "        return w.isupper() and len(w) > 1\n",
    "    def make(w):\n",
    "#         print(w[6])\n",
    "        return {\n",
    "            \"file\": file,\n",
    "            \"lemma\": w[6].lower(),\n",
    "            \"forms\": filter_forms(pars_grammar(w[7]))\n",
    "#             \"forms\": pars_grammar(w[7])\n",
    "        }\n",
    "    with open(path_data + file, 'r') as f:\n",
    "        gen = csv.reader(f, delimiter=';')\n",
    "        return [make(w) for w in itertools.islice(gen, limit) if _filter(w[6])]\n",
    "# [v[\"forms\"] for v in load_node()]\n",
    "len(load_node(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file': 'texts/BT/node.csv', 'lemma': 'abal', 'forms': ['afol', 'es']},\n",
       " {'file': 'texts/BT/node.csv', 'lemma': 'ac', 'forms': ['ach', 'ah', 'oc']},\n",
       " {'file': 'texts/BT/node.csv', 'lemma': 'ac', 'forms': ['e', 'ǽc']},\n",
       " {'file': 'texts/BT/node.csv',\n",
       "  'lemma': 'acan',\n",
       "  'forms': ['acaþ',\n",
       "   'acen',\n",
       "   'he ace',\n",
       "   'he æceþ',\n",
       "   'ic',\n",
       "   'ic ace',\n",
       "   'æcst',\n",
       "   'æcþ',\n",
       "   'ðú',\n",
       "   'ðú æcest',\n",
       "   'óc',\n",
       "   'ócon']},\n",
       " {'file': 'texts/BT/node.csv', 'lemma': 'ad', 'forms': ['aad', 'es']},\n",
       " {'file': 'texts/BT/node.csv',\n",
       "  'lemma': 'adl',\n",
       "  'forms': ['an', 'ádel', 'ádle']},\n",
       " {'file': 'texts/BT/node.csv', 'lemma': 'æcer', 'forms': ['es', 'æcyr']},\n",
       " {'file': 'texts/BT/node.csv',\n",
       "  'lemma': 'æfen',\n",
       "  'forms': ['es', 'éfen', 'ǽfyn']},\n",
       " {'file': 'texts/BT/node.csv', 'lemma': 'æfer', 'forms': []},\n",
       " {'file': 'texts/BT/node.csv',\n",
       "  'lemma': 'æg',\n",
       "  'forms': ['asges', 'ægra', 'ægru', 'æig']},\n",
       " {'file': 'texts/BT/node.csv', 'lemma': 'æl', 'forms': ['es']},\n",
       " {'file': 'texts/BT/node.csv', 'lemma': 'ælf', 'forms': ['es']},\n",
       " {'file': 'texts/BT/node.csv', 'lemma': 'ælmesse', 'forms': ['an', 'ælmysse']},\n",
       " {'file': 'texts/BT/node.csv',\n",
       "  'lemma': 'æppel',\n",
       "  'forms': ['apl', 'appel', 'eapl', 'es', 'æpl', 'æppla.', 'æpplas']},\n",
       " {'file': 'texts/BT/node.csv', 'lemma': 'æs', 'forms': ['es']},\n",
       " {'file': 'texts/BT/node.csv',\n",
       "  'lemma': 'æsc',\n",
       "  'forms': ['asca', 'ascas', 'ascum', 'æsca', 'æscas', 'æsces', 'æscum']},\n",
       " {'file': 'texts/BT/node.csv', 'lemma': 'æsp', 'forms': ['an', 'e', 'æspe']},\n",
       " {'file': 'texts/BT/node.csv', 'lemma': 'æt', 'forms': []},\n",
       " {'file': 'texts/BT/node.csv', 'lemma': 'æþm', 'forms': ['es', 'éðm']}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_node(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': 'ang.txt',\n",
       " 'lemma': 'feohtan',\n",
       " 'forms': ['feaht',\n",
       "  'feoht',\n",
       "  'feohtan',\n",
       "  'feohtaþ',\n",
       "  'feohte',\n",
       "  'feohten',\n",
       "  'feohtende',\n",
       "  'fieht',\n",
       "  'fiehtst',\n",
       "  'fohten',\n",
       "  'fuhte',\n",
       "  'fuhten',\n",
       "  'fuhton']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_array(base, add):\n",
    "    def to_set(arr):\n",
    "        return set(e[\"lemma\"] for e in arr)\n",
    "    diff = to_set(add).difference(to_set(base))\n",
    "    diff_arr = [v for v in add if v[\"lemma\"] in diff]\n",
    "    return base + diff_arr\n",
    "merge_array(load_dict(), load_oe())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bryttas',\n",
       " 'Crist',\n",
       " 'Dene',\n",
       " 'Engle',\n",
       " 'Englisc',\n",
       " 'Nazarenisc',\n",
       " 'Seaxisc',\n",
       " 'Wendlas',\n",
       " 'a',\n",
       " 'abarimathia']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sort_dict(arr):\n",
    "    def get_key(v):\n",
    "        return v[\"lemma\"]\n",
    "    arr.sort(key=get_key)\n",
    "    return arr\n",
    "[v['lemma'] for v in sort_dict(merge_array(load_dict(), load_oe()))[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': 'ang.txt',\n",
       " 'lemma': 'Bryttas',\n",
       " 'forms': ['Brytta', 'Bryttas', 'Bryttum']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_all():\n",
    "    return sort_dict(merge_array(load_dict(), load_oe()))\n",
    "get_all()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cltk(arr, file='out.txt'):\n",
    "    with open(file, 'w') as f:\n",
    "        for v in arr:\n",
    "            for w in v[\"forms\"]:\n",
    "                s = f'{v[\"lemma\"]}\\t{w}\\n'\n",
    "                f.write(s)\n",
    "            f.write(\"\\n\")\n",
    "save_cltk(get_all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict(arr, file='out_dict.txt'):\n",
    "    with open(file, 'w') as f:\n",
    "        for v in arr:\n",
    "            f.write(f'{v[\"lemma\"]}\\t{\"|\".join(v[\"forms\"])}\\n')\n",
    "save_dict(get_all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict((w for w in merge_array(get_all(), load_node()) if w['file'] == 'datasets/node.csv'), file='out_node.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6367"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_cltk((w for w in merge_array(get_all(), load_node()) if w['file'] == 'datasets/node.csv'), file='out_node2.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "toc-autonumbering": true,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
